{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNq5Yl6QDO2IpKhOhvuEHGi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AnanyaGupta24/PortfolioOptimization/blob/main/Optimizer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Overall, this code sets up an authenticated connection to Google Drive API that allows the user to access and manage files stored in their Google Drive account programmatically."
      ],
      "metadata": {
        "id": "FPF-eCajD4pO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "onAPD2mZ9YZP"
      },
      "outputs": [],
      "source": [
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "\n",
        "# Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code is used in Google Colab to link and download datasets from Google Drive into the Colab environment. It downloads CSV files from Google Drive that are stored in different URLs.\n",
        "\n",
        "Once this code is executed, the files will be downloaded from Google Drive and saved in the Colab environment, allowing the user to access and analyze the data."
      ],
      "metadata": {
        "id": "vHWwoQsBE8sB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#This part linkes the dataset in the drive to the google colab file\n",
        "link =  'Link here'\n",
        "link2 = 'Link here'\n",
        "link3 = 'Link here'\n",
        "\n",
        "id = link.split('/')[-2]\n",
        "id2 = link2.split('/')[-2]\n",
        "id3 = link3.split('/')[-2]\n",
        "# id4 = link4.split('/')[-2]\n",
        "\n",
        "downloaded = drive.CreateFile({'id' : id})\n",
        "downloaded2 = drive.CreateFile({'id' : id2})\n",
        "downloaded3 = drive.CreateFile({'id' : id3})\n",
        "\n",
        "downloaded.GetContentFile('y_dataset.csv')\n",
        "downloaded2.GetContentFile('LR_Predicted_Prices.csv')\n",
        "downloaded3.GetContentFile('LR_Actual_prices.csv')\n"
      ],
      "metadata": {
        "id": "HoELhHxl9eBW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code reads the S&P 500 index data from a CSV file stored in Google Drive."
      ],
      "metadata": {
        "id": "SLzuuLPRFLwp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#S&P 500 Data\n",
        "link = 'link here'\n",
        "id3 = link.split('/')[-2]\n",
        "downloaded3 = drive.CreateFile({'id' : id3})\n",
        "downloaded3.GetContentFile('SP500.csv')\n",
        "SP500 = pd.read_csv(\"SP500.csv\")\n"
      ],
      "metadata": {
        "id": "oz9PkJto9gg1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "All data sets are converted to pandas data frames, and their indices are set to the date columns."
      ],
      "metadata": {
        "id": "nvedMBM7lkFp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "\n",
        "Closing_Prices = pd.read_csv('y_dataset.csv')\n",
        "Closing_Prices['Date'] =  pd.to_datetime(Closing_Prices['Date'])\n",
        "Closing_Prices=Closing_Prices.set_index('Date')\n",
        "\n",
        "#Model: Linear Regression\n",
        "LR_Predicted_Prices = pd.read_csv('LR_Predicted_Prices.csv')\n",
        "LR_Predicted_Prices['Date'] =  pd.to_datetime(LR_Predicted_Prices['Date'])\n",
        "LR_Predicted_Prices=LR_Predicted_Prices.set_index('Date')\n",
        "\n",
        "LR_Actual_Prices = pd.read_csv('LR_Actual_prices.csv')\n",
        "LR_Actual_Prices['Date'] =  pd.to_datetime(LR_Actual_Prices['Date'])\n",
        "LR_Actual_Prices=LR_Actual_Prices.set_index('Date')\n"
      ],
      "metadata": {
        "id": "9AXNGreq9igW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code computes the log returns of the predicted and actual prices for the model as well as the log returns of the actual closing prices."
      ],
      "metadata": {
        "id": "jhTm9L9Rl2im"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Computing Log Returns\n",
        "PCA_Predicted_Returns = PCA_Predicted_Prices.apply(lambda x: np.log(x) - np.log(x.shift(1))).iloc[1:]\n",
        "PCA_Actual_Returns = PCA_Actual_Prices.apply(lambda x: np.log(x) - np.log(x.shift(1))).iloc[1:]\n",
        "\n",
        "LR_Predicted_Returns = LR_Predicted_Prices.apply(lambda x: np.log(x) - np.log(x.shift(1))).iloc[1:]\n",
        "LR_Actual_Returns = LR_Actual_Prices.apply(lambda x: np.log(x) - np.log(x.shift(1))).iloc[1:]\n",
        "\n",
        "Closing_Prices_Returns = Closing_Prices.apply(lambda x: np.log(x) - np.log(x.shift(1))).iloc[1:]\n",
        ""
      ],
      "metadata": {
        "id": "W5ab6Zus9l6q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To compute the mean squared error (MSE) between the actual and predicted prices obtained from the PCA model. The MSE is a commonly used metric to evaluate the accuracy of a regression model. It measures the average of the squares of the differences between predicted and actual values. The higher the value of the MSE, the worse the model's performance."
      ],
      "metadata": {
        "id": "aBm7PNp4mT6_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "mean_squared_error(PCA_Actual_Prices, PCA_Predicted_Prices)"
      ],
      "metadata": {
        "id": "pk9ZKJSN9pBP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Creation of Different Lookback and Forward Windows**"
      ],
      "metadata": {
        "id": "K9xqc53T9rmb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Mean Returns function\n",
        "def mean_returns(df, length):\n",
        "  mu = df.sum(axis = 0)/length\n",
        "  return mu"
      ],
      "metadata": {
        "id": "k9fTnFdh9sne"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code defines a window generator function that splits a given pandas dataframe into multiple datasets with a lookback period and a forward-looking period. The function takes in the following parameters:\n",
        "\n",
        "1. dataframe: a pandas dataframe with a DateTimeIndex.\n",
        "2. lookback: an integer representing the number of months to look back for each window.\n",
        "3. horizon: an integer representing the number of months to look forward for each window.\n",
        "4. step: an integer representing the number of months to step forward after each window.\n",
        "5. cummulative: a boolean value indicating whether the windows should be cumulative or not.\n",
        "\n",
        "The function first defines a helper function called monthdelta that takes a date and a delta (in months) and returns a new date with the delta months added to the original date. The function handles leap years correctly.\n",
        "\n",
        "The function then initializes a list to hold the windows and horizons, sets the initial window start to the earliest date in the dataframe, and then loops through the dates in the dataframe. For each date, the function determines the start and end dates for the lookback window and the horizon window using the monthdelta function. It then extracts the corresponding data and appends it to the windows and horizons lists.\n",
        "\n",
        "The function returns two lists: the windows and the horizons, where each element of the windows list is a dataframe representing a lookback window and each element of the horizons list is a dataframe representing the corresponding horizon window.\n"
      ],
      "metadata": {
        "id": "xo-WrTEEnDkV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import timedelta\n",
        "from dateutil.parser import parse\n",
        "\n",
        "def monthdelta(date, delta):\n",
        "    m, y = (date.month+delta) % 12, date.year + ((date.month)+delta-1) // 12\n",
        "    if not m: m = 12\n",
        "    d = min(date.day, [31,\n",
        "        29 if y%4==0 and not y%400==0 else 28,31,30,31,30,31,31,30,31,30,31][m-1])\n",
        "    new_date = (date.replace(day=d,month=m, year=y))\n",
        "    return parse(new_date.strftime('%Y-%m-%d'))\n",
        "\n",
        "\n",
        "#This part of the code takes in a dataset and splits it into datasets w/ lookback months and forward looking months\n",
        "def windowGenerator (dataframe, lookback, horizon,\n",
        "                    step, cummulative = False):\n",
        "\n",
        "#takes pandas dataframe with DatetimeIndex\n",
        "\n",
        "    if cummulative:\n",
        "        c = lookback\n",
        "        step = horizon\n",
        "\n",
        "    initial = min(dataframe.index)\n",
        "    windows = []\n",
        "    horizons = []\n",
        "\n",
        "    while initial <= monthdelta(max(dataframe.index), -lookback):\n",
        "        windowStart = initial\n",
        "        windowEnd = monthdelta(windowStart, lookback)\n",
        "        if cummulative:\n",
        "            windowStart = min(dataframe.index)\n",
        "            windowEnd = monthdelta(windowStart, c) + timedelta(days=1)\n",
        "            c += horizon\n",
        "        horizonStart = windowEnd + timedelta(days=1)\n",
        "        horizonEnd = monthdelta(horizonStart, horizon)\n",
        "\n",
        "        lookbackWindow = dataframe[windowStart:windowEnd]\n",
        "        horizonWindow = dataframe[horizonStart:horizonEnd]\n",
        "\n",
        "        windows.append(lookbackWindow)\n",
        "        horizons.append(horizonWindow)\n",
        "\n",
        "        initial = monthdelta(initial, step)\n",
        "\n",
        "    return windows, horizons"
      ],
      "metadata": {
        "id": "CXhpLLif9uhH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Optimize Function**"
      ],
      "metadata": {
        "id": "hY6X2bxK93Sp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The actual_return function takes in actual returns data and a set of portfolio weights, and calculates the portfolio returns and variance.\n",
        "\n",
        "The scipy_opt function takes in predicted returns data, actual returns data, and two regularization parameters (lam1 and lam2). It performs portfolio optimization using the predicted returns data and the f cost function, which is defined as the negative of the expected portfolio return minus lam1 times the portfolio variance plus lam2 times the L1 norm (the sum of the absolute vector values) of the portfolio weights.\n",
        "The function uses the SciPy optimization library to find the portfolio weights that maximize this cost function, subject to the constraint that the sum of the weights equals 1.\n",
        "The resulting portfolio weights are then used to calculate the predicted portfolio returns and variance, as well as the actual portfolio returns, variance, and Sharpe ratio (calculated as the actual portfolio returns divided by the standard deviation of the actual portfolio returns)."
      ],
      "metadata": {
        "id": "CIOXC-OSnVZe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.optimize import minimize, Bounds, LinearConstraint\n",
        "from numpy.linalg import norm\n",
        "\n",
        "def actual_return(actual_returns, w):\n",
        "  actual_returns = actual_returns\n",
        "  mean_return = mean_returns(actual_returns, actual_returns.shape[0])\n",
        "  actual_covariance = actual_returns.cov()\n",
        "\n",
        "  portfolio_returns = mean_return.T.dot(w)\n",
        "  portfolio_variance = w.T.dot(actual_covariance).dot(w)\n",
        "  return portfolio_returns, portfolio_variance\n",
        "\n",
        "\n",
        "#Input entire predicted returns df, actual returns df, starting date\n",
        "def scipy_opt(predicted_returns, actual_returns, lam1, lam2):\n",
        "  mean_return = mean_returns(predicted_returns, predicted_returns.shape[0])\n",
        "  predicted_covariance = predicted_returns.cov()\n",
        "\n",
        "  #Cost Function\n",
        "  def f(w):\n",
        "    return -(mean_return.T.dot(w) - lam1*(w.T.dot(predicted_covariance).dot(w)) + lam2*norm(w, ord=1))\n",
        "  #out custom maximises\n",
        "\n",
        "  #Bounds of Weights\n",
        "  opt_bounds = Bounds(0, 1)\n",
        "\n",
        "  #Equality Constraints\n",
        "  def h(w):\n",
        "    return sum(w) - 1\n",
        "\n",
        "  #Constraints Dictionary\n",
        "  cons = ({\n",
        "      'type' : 'eq',\n",
        "      'fun' : lambda w: h(w)\n",
        "  })\n",
        "\n",
        "  #Solver\n",
        "  sol = minimize(f,\n",
        "                 x0 = np.ones(mean_return.shape[0]),\n",
        "                 constraints = cons,\n",
        "                 bounds = opt_bounds,\n",
        "                 options = {'disp': False},\n",
        "                 tol=10e-10)\n",
        "\n",
        "\n",
        "  #Predicted Results\n",
        "  w = sol.x\n",
        "  predicted_portfolio_returns = w.dot(mean_return)\n",
        "  portfolio_STD = w.T.dot(predicted_covariance).dot(w)\n",
        "\n",
        "  #Actual Results\n",
        "  portfolio_actual_returns, portfolio_actual_variance = actual_return(actual_returns, w)\n",
        "  sharpe_ratio = portfolio_actual_returns/np.std(portfolio_actual_variance)\n",
        "\n",
        "  ret_dict = {'weights' : w,\n",
        "              'predicted_returns' : predicted_portfolio_returns,\n",
        "              'predicted_variance' : portfolio_STD,\n",
        "              'actual_returns' : portfolio_actual_returns,\n",
        "              'actual_variance' : portfolio_actual_variance,\n",
        "              'sharpe_ratio': sharpe_ratio}\n",
        "\n",
        "  return ret_dict"
      ],
      "metadata": {
        "id": "3Fbnad1v9xpR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "LR_pred_windows, LR_pred_horizons = windowGenerator(LR_Predicted_Returns, 12, 1, 1)\n",
        "LR_act_windows, LR_act_horizons = windowGenerator(LR_Actual_Returns, 12, 1, 1)"
      ],
      "metadata": {
        "id": "dzTO4orN-kXl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "LR_scipy_returns= []\n",
        "LR_scipy_variance = []\n",
        "LR_scipy_SR = []\n",
        "\n",
        "#Testing on 5 years of data\n",
        "for i in range(len(LR_act_horizons)-72,len(LR_act_horizons)-12):\n",
        "  #Scipy optimize results\n",
        "  scipy = scipy_opt(LR_pred_horizons[i], LR_act_horizons[i], .5, 2)\n",
        "  LR_scipy_returns.append(scipy['actual_returns'])\n",
        "  LR_scipy_variance.append(scipy['actual_variance'])\n",
        "  LR_scipy_SR.append(scipy['sharpe_ratio'])\n",
        "  # print(\"Month \" + str(i) + \" complete\")"
      ],
      "metadata": {
        "id": "YYatonam-mFL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "timestamps = []\n",
        "for i in range(len(LR_act_horizons)-72,len(LR_act_horizons)-12):\n",
        "  time = LR_act_horizons[i].index[-1]\n",
        "  timestamps.append(time)\n",
        "\n",
        "LR_Portfolio_Returns = pd.DataFrame(data = np.array([LR_scipy_returns,LR_scipy_variance,LR_scipy_SR]).T, columns = ['Returns', 'Variance', 'Sharpe Ratio'], index=timestamps)\n",
        ""
      ],
      "metadata": {
        "id": "gdQkYotD-oFP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Exporting the Dataset\n",
        "from google.colab import drive\n",
        "drive.mount('drive')\n",
        "\n",
        "LR_Portfolio_Returns.to_csv('LR_Portfolio_Returns.csv')\n",
        "!cp LR_Portfolio_Returns.csv \"drive/My Drive/Machine Learning Project/ML Section Expo"
      ],
      "metadata": {
        "id": "7P3ujh2K-y6v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Diagnostics**\n",
        "The calculation for seeing how much the portfolio grows in dollar terms:\n",
        "\n",
        "Given $100, our equity graph shows how much our portfolio value increase (or decreases)"
      ],
      "metadata": {
        "id": "XsWnZPRJ_fu2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "LR_equity = [100]\n",
        "\n",
        "#This is the calculation for the for seeing how much the portfolio grows\n",
        "for i in range(1,60):\n",
        "  LR_equity.append(LR_equity[i-1]* math.exp(LR_scipy_returns[i]))\n",
        ""
      ],
      "metadata": {
        "id": "idfwIqnI_hjs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plots line graph b/w years and equity\n",
        "plt.plot(timestamps, LR_equity, label = \"Linear Regression\")\n",
        "plt.title(\"Equity Graph\")\n",
        "plt.legend()\n",
        "plt.show();"
      ],
      "metadata": {
        "id": "sCyz8i6F_jx7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Linear Regression Ending Equity: \" , LR_equity[-1])\\"
      ],
      "metadata": {
        "id": "lgSKmzY0_sPy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "def metrics(returns):\n",
        "  sharpe = returns.mean() / returns.std()\n",
        "  annualized_sharpe = sharpe.item() / math.sqrt(252)\n",
        "\n",
        "  stdev = returns.std()\n",
        "  annualized_vol = stdev.item() / math.sqrt(252)\n",
        "\n",
        "\n",
        "  return {\"Annualized Sharpe Ratio\": annualized_sharpe,\n",
        "          \"Annualized Volatility\": annualized_vol}"
      ],
      "metadata": {
        "id": "wI3DQh4p_s8J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Annualized info for Linear Regression\n",
        "metrics(np.array(LR_scipy_returns))"
      ],
      "metadata": {
        "id": "Vjb4CCtM_xG_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}